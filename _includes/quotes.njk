{# 
  Quotes page template - used by both language versions
  This template extends the base layout and includes quotes from AI safety experts.
  Language-specific content comes from i18n translation files.
#}
{% extends "base.njk" %}

{% block content %}
<div class="page-header quotes-header">
  <div class="bg-element bg-element-1"></div>
  <div class="bg-element bg-element-2"></div>
  <div class="container">
    <h1>{{ title }}</h1>
    <p>{{ description }}</p>
  </div>
</div>

<section class="content-section quotes-overview">
  <div class="container">
    <p class="intro-text">
      {% if lang == "en" %}
        The following quotes from industry leaders, researchers, and prominent figures highlight the importance of AI safety and the potential risks of advanced artificial intelligence.
      {% else %}
        Følgende sitater fra bransjeldere, forskere og fremtredende personer understreker viktigheten av AI-sikkerhet og de potensielle risikoene ved avansert kunstig intelligens.
      {% endif %}
    </p>

    <div class="quotes-collection">
      <!-- All quotes listed -->
      {% if lang == "en" %}
        {% for quote in [
          {
            "content": "I think at the extreme end is the Nick Bostrom style of fear that an AGI could destroy humanity. I can't see any reason in principle why that couldn't happen.",
            "author": "Dario Amodei",
            "title": "Co-founder & CEO, Anthropic",
            "date": "Jul 2017",
            "source": "https://80000hours.org/podcast/episodes/the-world-needs-ai-researchers-heres-how-to-become-one/"
          },
          {
            "content": "Mark my words — AI is far more dangerous than nukes.",
            "author": "Elon Musk",
            "title": "CEO, Tesla, SpaceX & xAI",
            "date": "Mar 2018",
            "source": "https://www.cnbc.com/2018/03/13/elon-musk-at-sxsw-a-i-is-more-dangerous-than-nuclear-weapons.html"
          },
          {
            "content": "We need to use the engineering to bootstrap ourselves into a science of AIs before we build the super intelligent AI so that it doesn't kill us all.",
            "author": "Emmet Shear",
            "title": "Founder & CEO, Twitch.tv; former Interim CEO of OpenAI",
            "date": "Jun 2023",
            "source": "https://blog.biocomm.ai/2025/03/28/what-leaders-say-about-ai/"
          },
          {
            "content": "I think it's important that people understand it's not just science fiction; it's not just fear-mongering – it is a real risk that we need to think about, and we need to figure out in advance how to deal with it.",
            "author": "Geoffrey Hinton",
            "title": "Godfather of AI, Nobel Prize Winner",
            "date": "Jun 2023",
            "source": "https://www.utoronto.ca/news/risks-artificial-intelligence-must-be-considered-technology-evolves-geoffrey-hinton"
          },
          {
            "content": "OpenAI is training ever-more-powerful AI systems with the goal of eventually surpassing human intelligence across the board. This could be the best thing that has ever happened to humanity, but it could also be the worst if we don't proceed with care.",
            "author": "Daniel Kokotajlo",
            "title": "Former OpenAI Researcher & AI Safety Advocate",
            "date": "May 2024",
            "source": "https://www.vox.com/future-perfect/2024/5/17/24158403/openai-resignations-ai-safety-ilya-sutskever-jan-leike-artificial-intelligence"
          },
          {
            "content": "I joined with substantial hope that OpenAI would rise to the occasion and behave more responsibly as they got closer to achieving AGI. It slowly became clear to many of us that this would not happen. I gradually lost trust in OpenAI leadership and their ability to responsibly handle AGI, so I quit.",
            "author": "Daniel Kokotajlo",
            "title": "Former OpenAI Researcher & AI Safety Advocate",
            "date": "May 2024",
            "source": "https://www.vox.com/future-perfect/2024/5/17/24158403/openai-resignations-ai-safety-ilya-sutskever-jan-leike-artificial-intelligence"
          },
          {
            "content": "Development of superhuman machine intelligence (SMI) is probably the greatest threat to the continued existence of humanity.",
            "author": "Sam Altman",
            "title": "CEO, OpenAI",
            "date": "Feb 2015",
            "source": "https://blog.samaltman.com/machine-intelligence-part-1"
          },
          {
            "content": "Success in creating AI would be the biggest event in human history. Unfortunately, it might also be the last, unless we learn how to avoid the risks.",
            "author": "Stephen Hawking",
            "title": "Physicist & Cosmologist",
            "date": "May 2014",
            "source": "https://www.cam.ac.uk/research/news/the-best-or-worst-thing-to-happen-to-humanity-stephen-hawking-launches-centre-for-the-future-of"
          },
          {
            "content": "We can still regulate the new AI tools, but we must act quickly. Whereas nukes cannot invent more powerful nukes, AI can make exponentially more powerful AI.",
            "author": "Yuval Noah Harari",
            "title": "Historian & Author",
            "date": "Apr 2023",
            "source": "https://www.economist.com/by-invitation/2023/04/28/yuval-noah-harari-argues-that-ai-has-hacked-the-operating-system-of-human-civilisation"
          },
          {
            "content": "My chance that something goes really quite catastrophically wrong on the scale of human civilization might be somewhere between 10 per cent and 25 per cent.",
            "author": "Dario Amodei",
            "title": "Co-founder & CEO, Anthropic",
            "date": "Oct 2023",
            "source": "https://www.indy100.com/science-tech/ai-extinction-chance-humans"
          },
          {
            "content": "The development of full artificial intelligence could spell the end of the human race... It would take off on its own, and re-design itself at an ever increasing rate.",
            "author": "Stephen Hawking",
            "title": "Physicist & Cosmologist",
            "date": "Dec 2014",
            "source": "https://www.bbc.com/news/technology-30290540"
          },
          {
            "content": "We are seeing the most destructive force in history here. We will have something that is smarter than the smartest human.",
            "author": "Elon Musk",
            "title": "CEO, Tesla, SpaceX & xAI",
            "date": "Nov 2023",
            "source": "https://www.newscientist.com/article/2401101-elon-musks-ai-chat-with-rishi-sunak-everything-you-need-to-know/"
          },
          {
            "content": "The concern is really that we will build machines that are so much more competent than we are that the slightest divergence between their goals and our own could destroy us.",
            "author": "Sam Harris",
            "title": "Philosopher & Author",
            "date": "Oct 2016",
            "source": "https://www.ted.com/talks/sam_harris_can_we_build_ai_without_losing_control_over_it"
          },
          {
            "content": "It's coming, either way it's coming very soon and I'm not sure society's quite ready for that yet.",
            "author": "Demis Hassabis",
            "title": "CEO, Google DeepMind; Nobel Prize Winner",
            "date": "Apr 2024",
            "source": "https://www.ndtv.com/science/google-deepmind-ceo-on-what-keeps-him-up-at-night-agi-is-coming-societys-not-ready-8245874"
          },
          {
            "content": "One of the biggest risks to the future of civilization is AI.",
            "author": "Elon Musk",
            "title": "CEO, Tesla, SpaceX & xAI",
            "date": "Feb 2023",
            "source": "https://www.cnbc.com/2023/02/15/elon-musk-co-founder-of-chatgpt-creator-openai-warns-of-ai-society-risk.html"
          },
          {
            "content": "The bad case — and I think this is important to say — is like lights out for all of us.",
            "author": "Sam Altman",
            "title": "CEO, OpenAI",
            "date": "Jan 2023",
            "source": "https://www.businessinsider.com/chatgpt-openai-ceo-worst-case-ai-lights-out-for-all-2023-1"
          },
          {
            "content": "I am in the camp that is concerned about super intelligence. First the machines will do a lot of jobs for us and not be super intelligent. A few decades after that though the intelligence is strong enough to be a concern.",
            "author": "Bill Gates",
            "title": "Co-founder, Microsoft",
            "date": "Jan 2015",
            "source": "https://www.reddit.com/r/IAmA/comments/2tzjp7/hi_reddit_im_bill_gates_and_im_back_for_my_third/"
          },
          {
            "content": "We are finding new jailbreaks. Every day people jailbreak Claude, they jailbreak the other models. [...] I'm actually deeply concerned that in two or three years, we'll get to the point where the models can, I don't know, do very dangerous things with science, engineering, biology, and then a jailbreak could be life or death.",
            "author": "Dario Amodei",
            "title": "Co-founder & CEO, Anthropic",
            "date": "Jul 2023",
            "source": "https://www.nytimes.com/2023/07/21/podcasts/dario-amodei-ceo-of-anthropic-on-the-paradoxes-of-ai-safety-and-netflixs-deep-fake-love.html"
          },
          {
            "content": "It's hard to see how you can prevent the bad actors from using it for bad things. I think we need to worry a lot about that.",
            "author": "Geoffrey Hinton",
            "title": "AI Pioneer, Turing Award Winner",
            "date": "May 2023",
            "source": "https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html"
          },
          {
            "content": "We must take the risks of AI as seriously as other major global challenges, like climate change [...] It took the international community too long to coordinate an effective global response to this, and we're living with the consequences of that now. We can't afford the same delay with AI.",
            "author": "Demis Hassabis",
            "title": "CEO, Google DeepMind; Nobel Prize Winner",
            "date": "Oct 2023",
            "source": "https://futurism.com/the-byte/google-ai-boss-existential-threat"
          },
          {
            "content": "Powerful AI systems have a good chance of deliberately and irreversibly disempowering humanity. This is a much more likely failure mode than humanity killing ourselves with destructive physical technologies.",
            "author": "Paul Christiano",
            "title": "AI Alignment Researcher",
            "date": "Jun 2022",
            "source": "https://www.alignmentforum.org/posts/CoZhXrhpQxpy9xw9y/where-i-agree-and-disagree-with-eliezer"
          },
          {
            "content": "I take the existential risk scenario seriously enough that I would pause it.",
            "author": "Sam Harris",
            "title": "Philosopher & Author",
            "date": "Aug 2023",
            "source": "https://www.getsurrey.co.uk/news/uk-world-news/scientist-says-artificial-intelligence-could-27496320"
          },
          {
            "content": "If I see international coordination doesn't happen, or much of it, it'll be more likely than not that we go extinct.",
            "author": "Dan Hendrycks",
            "title": "Director, Center for AI Safety",
            "date": "Jul 2023",
            "source": "https://abcnews.go.com/Technology/dispute-threat-extinction-posed-ai-looms-surging-industry/story?id=101495898"
          },
          {
            "content": "If you build something that is a lot smarter than us, not like somewhat smarter… but like it's much smarter than we are as we are than like dogs right, like a big jump. That thing is intrinsically pretty dangerous.",
            "author": "Emmet Shear",
            "title": "Founder & CEO, Twitch.tv; former Interim CEO of OpenAI",
            "date": "Jun 2023",
            "source": "https://blog.biocomm.ai/2023/11/21/huffpost-new-openai-leaders-chilling-doom-warning-may-scare-your-pants-off-emmett-shear-voiced-his-concerns-about-the-dangers-of-artificial-intelligence-in-a-resurfaced-clip-20-nov/"
          },
          {
            "content": "An AI wouldn't necessarily have to hate us or or want to kill us we might just you know be in the way or irrelevant to whatever alien goal it has.",
            "author": "Scott Aaronson",
            "title": "Professor of Computer Science, UT Austin",
            "date": "Mar 2024",
            "source": "https://www.youtube.com/watch?feature=shared&v=XgCHZ1G93iA"
          },
          {
            "content": "while we are racing towards AGI or even ASI, nobody currently knows how such an AGI or ASI could be made to behave morally, or at least behave as intended by its developers and not turn against humans",
            "author": "Yoshua Bengio",
            "title": "Deep Learning Pioneer, Turing Award Winner",
            "date": "Jul 2024",
            "source": "https://yoshuabengio.org/2024/07/09/reasoning-through-arguments-against-taking-ai-safety-seriously/"
          },
          {
            "content": "Since we don't really know how fast technological advances in AI or elsewhere (e.g., biotechnology) will come, it's best to get on with the task of better regulating these kinds of powerful tools right away.",
            "author": "Yoshua Bengio",
            "title": "Deep Learning Pioneer, Turing Award Winner",
            "date": "Jan 2022",
            "source": "https://yoshuabengio.org/2022/01/24/superintelligence-futurology-vs-science/"
          },
          {
            "content": "We are as a matter of fact, right now, building creepy, super-capable, amoral, psychopaths that never sleep, think much faster than us, can make copies of themselves and have nothing human about them whatsoever, what could possibly go wrong?",
            "author": "Max Tegmark",
            "title": "Professor, MIT; AI Safety Researcher",
            "date": "Nov 2023",
            "source": "https://www.facebook.com/futureoflifeinstitute/posts/we-are-right-now-building-creepy-super-capable-amoral-psychopaths-that-never-sle/691751266435495/"
          },
          {
            "content": "Even if we \"win\" the global race to develop these uncontrollable AI systems, we risk losing our social stability, security, and possibly even our species in the process.",
            "author": "Max Tegmark",
            "title": "Professor, MIT; AI Safety Researcher",
            "date": "Oct 2023",
            "source": "https://futureoflife.org/open-letters/written-statement-of-dr-max-tegmark-to-the-ai-insight-forum/"
          }
        ] %}
          <div class="quote-card-large">
            <div class="quote-content">
              <p>{{ quote.content }}</p>
              <div class="quote-date-source">{{ quote.date }} - <a href="{{ quote.source }}" target="_blank" rel="noopener noreferrer">Source</a></div>
            </div>
            <div class="quote-attribution">
              <div>
                <div class="quote-author">{{ quote.author }}</div>
                <div class="quote-title">{{ quote.title }}</div>
              </div>
            </div>
          </div>
        {% endfor %}
      {% else %}
        {% for quote in [
          {
            "content": "Jeg tror at i ytterste konsekvens er det en Nick Bostrom-type frykt for at en AGI kunne utslette menneskeheten. Jeg kan ikke se noen prinsipiell grunn til at det ikke kunne skje.",
            "author": "Dario Amodei",
            "title": "Medgründer og adm. direktør, Anthropic",
            "date": "Jul 2017",
            "source": "https://80000hours.org/podcast/episodes/the-world-needs-ai-researchers-heres-how-to-become-one/"
          },
          {
            "content": "Merk mine ord — AI er langt farligere enn atomvåpen.",
            "author": "Elon Musk",
            "title": "Adm. direktør, Tesla, SpaceX og xAI",
            "date": "Mar 2018",
            "source": "https://www.cnbc.com/2018/03/13/elon-musk-at-sxsw-a-i-is-more-dangerous-than-nuclear-weapons.html"
          },
          {
            "content": "Vi må bruke ingeniørarbeidet til å løfte oss selv opp til en vitenskap om AI-er før vi bygger den superintelligente AI-en, slik at den ikke dreper oss alle.",
            "author": "Emmet Shear",
            "title": "Grunnlegger og adm. direktør, Twitch.tv; tidligere midlertidig adm. direktør for OpenAI",
            "date": "Jun 2023",
            "source": "https://blog.biocomm.ai/2025/03/28/what-leaders-say-about-ai/"
          },
          {
            "content": "Jeg tror det er viktig at folk forstår at dette ikke bare er science fiction; det er ikke bare fryktretorikk – det er en reell risiko som vi må tenke på, og vi må finne ut på forhånd hvordan vi skal håndtere den.",
            "author": "Geoffrey Hinton",
            "title": "AI-gudfar, Turing og Nobel-prisvinner",
            "date": "Jun 2023",
            "source": "https://www.utoronto.ca/news/risks-artificial-intelligence-must-be-considered-technology-evolves-geoffrey-hinton"
          },
          {
            "content": "OpenAI trener stadig kraftigere AI-systemer med målet om til slutt å overgå menneskelig intelligens på alle områder. Dette kan være det beste som noensinne har skjedd menneskeheten, men det kan også være det verste hvis vi ikke går frem med forsiktighet.",
            "author": "Daniel Kokotajlo",
            "title": "Tidligere OpenAI-forsker og AI-sikkerhetsadvokat",
            "date": "Mai 2024",
            "source": "https://www.vox.com/future-perfect/2024/5/17/24158403/openai-resignations-ai-safety-ilya-sutskever-jan-leike-artificial-intelligence"
          },
          {
            "content": "Jeg begynte med betydelig håp om at OpenAI ville stille opp og oppføre seg mer ansvarlig når de kom nærmere å oppnå AGI. Det ble gradvis klart for mange av oss at dette ikke ville skje. Jeg mistet gradvis tillit til OpenAI-ledelsen og deres evne til å håndtere AGI på en ansvarlig måte, så jeg sa opp.",
            "author": "Daniel Kokotajlo",
            "title": "Tidligere OpenAI-forsker og AI-sikkerhetsadvokat",
            "date": "Mai 2024",
            "source": "https://www.vox.com/future-perfect/2024/5/17/24158403/openai-resignations-ai-safety-ilya-sutskever-jan-leike-artificial-intelligence"
          },
          {
            "content": "Utvikling av overmennskelig maskinintellekt er sannsynligvis den største trusselen mot menneskehetens fortsatte eksistens.",
            "author": "Sam Altman",
            "title": "Administrerende direktør, OpenAI",
            "date": "Feb 2015",
            "source": "https://blog.samaltman.com/machine-intelligence-part-1"
          },
          {
            "content": "Å lykkes med å skape AI vil være den største hendelsen i menneskehetens historie. Dessverre kan det også bli den siste, med mindre vi lærer å unngå risikoene.",
            "author": "Stephen Hawking",
            "title": "Fysiker og kosmolog",
            "date": "Mai 2014",
            "source": "https://www.cam.ac.uk/research/news/the-best-or-worst-thing-to-happen-to-humanity-stephen-hawking-launches-centre-for-the-future-of"
          },
          {
            "content": "Vi kan fortsatt regulere de nye AI-verktøyene, men vi må handle raskt. Mens atomvåpen ikke kan oppfinne kraftigere atomvåpen, kan AI skape eksponentielt kraftigere AI.",
            "author": "Yuval Noah Harari",
            "title": "Historiker og forfatter",
            "date": "Apr 2023",
            "source": "https://www.economist.com/by-invitation/2023/04/28/yuval-noah-harari-argues-that-ai-has-hacked-the-operating-system-of-human-civilisation"
          },
          {
            "content": "Min vurdering er at sjansen for at noe går virkelig katastrofalt galt på et nivå som truer den menneskelige sivilisasjon, kan være et sted mellom 10 og 25 prosent.",
            "author": "Dario Amodei",
            "title": "Medgründer og adm. direktør, Anthropic",
            "date": "Okt 2023",
            "source": "https://www.indy100.com/science-tech/ai-extinction-chance-humans"
          },
          {
            "content": "Utviklingen av fullstendig kunstig intelligens kan bety slutten for menneskeheten... Den vil ta av på egen hånd, og omdesigne seg selv i stadig økende tempo.",
            "author": "Stephen Hawking",
            "title": "Fysiker og kosmolog",
            "date": "Des 2014",
            "source": "https://www.bbc.com/news/technology-30290540"
          },
          {
            "content": "Vi ser den mest destruktive kraften i historien her. Vi vil få noe som er smartere enn det smarteste mennesket.",
            "author": "Elon Musk",
            "title": "Adm. direktør, Tesla, SpaceX og xAI",
            "date": "Nov 2023",
            "source": "https://www.newscientist.com/article/2401101-elon-musks-ai-chat-with-rishi-sunak-everything-you-need-to-know/"
          },
          {
            "content": "Bekymringen er virkelig at vi vil bygge maskiner som er så mye mer kompetente enn oss at selv den minste avvik mellom deres mål og våre egne kan ødelegge oss.",
            "author": "Sam Harris",
            "title": "Filosof og forfatter",
            "date": "Okt 2016",
            "source": "https://www.ted.com/talks/sam_harris_can_we_build_ai_without_losing_control_over_it"
          },
          {
            "content": "Det kommer, uansett kommer det veldig snart, og jeg er ikke sikker på at samfunnet er helt klar for det ennå.",
            "author": "Demis Hassabis",
            "title": "Administrerende direktør, Google DeepMind; Nobelprisvinner",
            "date": "Apr 2024",
            "source": "https://www.ndtv.com/science/google-deepmind-ceo-on-what-keeps-him-up-at-night-agi-is-coming-societys-not-ready-8245874"
          },
          {
            "content": "En av de største risikoene for fremtidens sivilisasjon er AI.",
            "author": "Elon Musk",
            "title": "Adm. direktør, Tesla, SpaceX og xAI",
            "date": "Feb 2023",
            "source": "https://www.cnbc.com/2023/02/15/elon-musk-co-founder-of-chatgpt-creator-openai-warns-of-ai-society-risk.html"
          },
          {
            "content": "I verste fall – og dette er viktig å påpeke – er det som å slukke lyset for oss alle.",
            "author": "Sam Altman",
            "title": "Administrerende direktør, OpenAI",
            "date": "Jan 2023",
            "source": "https://www.businessinsider.com/chatgpt-openai-ceo-worst-case-ai-lights-out-for-all-2023-1"
          },
          {
            "content": "Jeg er i den leiren som er bekymret for superintelligens. Først vil maskinene gjøre mange jobber for oss uten å være superintelligente. Noen tiår etter det vil intelligensen være sterk nok til å være en bekymring.",
            "author": "Bill Gates",
            "title": "Medgründer, Microsoft",
            "date": "Jan 2015",
            "source": "https://www.reddit.com/r/IAmA/comments/2tzjp7/hi_reddit_im_bill_gates_and_im_back_for_my_third/"
          },
          {
            "content": "Vi finner stadig nye sårbarheter. Hver dag er det noen som bryter sikkerhetsbegrensningene i Claude og andre modeller. [...] Jeg er faktisk dypt bekymret for at vi om to-tre år vil nå et punkt der modellene kan utføre svært farlige ting innen vitenskap, ingeniørarbeid, biologi, og da kan et sikkerhetsbrudd bli et spørsmål om liv eller død.",
            "author": "Dario Amodei",
            "title": "Medgründer og adm. direktør, Anthropic",
            "date": "Jul 2023",
            "source": "https://www.nytimes.com/2023/07/21/podcasts/dario-amodei-ceo-of-anthropic-on-the-paradoxes-of-ai-safety-and-netflixs-deep-fake-love.html"
          },
          {
            "content": "Det er vanskelig å se hvordan man kan hindre aktører med onde hensikter fra å bruke det til onde formål. Jeg tror vi må bekymre oss mye for det.",
            "author": "Geoffrey Hinton",
            "title": "KI-gudfar, Turing og Nobel-prisvinner",
            "date": "Mai 2023",
            "source": "https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html"
          },
          {
            "content": "Vi må ta risikoene ved AI like alvorlig som andre globale utfordringer, som klimaendringer [...] Det tok det internasjonale samfunnet for lang tid å koordinere en effektiv global respons på dette, og vi lever nå med konsekvensene. Vi har ikke råd til samme forsinkelse med AI.",
            "author": "Demis Hassabis",
            "title": "Administrerende direktør, Google DeepMind; Nobelprisvinner",
            "date": "Okt 2023",
            "source": "https://futurism.com/the-byte/google-ai-boss-existential-threat"
          },
          {
            "content": "Kraftige AI-systemer har en god sjanse til bevisst og irreversibelt å frata menneskeheten makt. Dette er en mye mer sannsynlig feilmodus enn at menneskeheten utsletter seg selv med destruktive fysiske teknologier.",
            "author": "Paul Christiano",
            "title": "AI Alignment-forsker",
            "date": "Jun 2022",
            "source": "https://www.alignmentforum.org/posts/CoZhXrhpQxpy9xw9y/where-i-agree-and-disagree-with-eliezer"
          },
          {
            "content": "Jeg tar scenariet med eksistensiell risiko alvorlig nok til at jeg ville pause utviklingen.",
            "author": "Sam Harris",
            "title": "Filosof og forfatter",
            "date": "Aug 2023",
            "source": "https://www.getsurrey.co.uk/news/uk-world-news/scientist-says-artificial-intelligence-could-27496320"
          },
          {
            "content": "Hvis jeg ser at internasjonal koordinering ikke skjer, eller skjer i liten grad, er det mer sannsynlig enn ikke at vi utryddes.",
            "author": "Dan Hendrycks",
            "title": "Direktør, Center for AI Safety",
            "date": "Jul 2023",
            "source": "https://abcnews.go.com/Technology/dispute-threat-extinction-posed-ai-looms-surging-industry/story?id=101495898"
          },
          {
            "content": "Hvis du bygger noe som er mye smartere enn oss, ikke bare litt smartere... men det er mye smartere enn vi er, som vi er i forhold til hunder, liksom, et stort sprang. Da er det i seg selv ganske farlig.",
            "author": "Emmet Shear",
            "title": "Grunnlegger og adm. direktør, Twitch.tv; tidligere midlertidig adm. direktør for OpenAI",
            "date": "Jun 2023",
            "source": "https://blog.biocomm.ai/2023/11/21/huffpost-new-openai-leaders-chilling-doom-warning-may-scare-your-pants-off-emmett-shear-voiced-his-concerns-about-the-dangers-of-artificial-intelligence-in-a-resurfaced-clip-20-nov/"
          },
          {
            "content": "En AI trenger ikke nødvendigvis å hate oss eller ønske å drepe oss, vi kan bare være i veien eller irrelevante for hvilket som helst fremmed mål den har.",
            "author": "Scott Aaronson",
            "title": "Professor i informatikk, UT Austin",
            "date": "Mar 2024",
            "source": "https://www.youtube.com/watch?feature=shared&v=XgCHZ1G93iA"
          },
          {
            "content": "mens vi raser mot AGI eller til og med ASI, vet ingen for øyeblikket hvordan en slik AGI eller ASI kan gjøres til å oppføre seg moralsk, eller i det minste oppføre seg som tiltenkt av utviklerne og ikke vende seg mot mennesker",
            "author": "Yoshua Bengio",
            "title": "Dyplæringspioner, Turing-prisvinner",
            "date": "Jul 2024",
            "source": "https://yoshuabengio.org/2024/07/09/reasoning-through-arguments-against-taking-ai-safety-seriously/"
          },
          {
            "content": "Siden vi ikke virkelig vet hvor raskt teknologiske fremskritt innen AI eller andre steder (f.eks. bioteknologi) vil komme, er det best å komme i gang med oppgaven med å bedre regulere disse typene kraftige verktøy med en gang.",
            "author": "Yoshua Bengio",
            "title": "Dyplæringspioner, Turing-prisvinner",
            "date": "Jan 2022",
            "source": "https://yoshuabengio.org/2022/01/24/superintelligence-futurology-vs-science/"
          },
          {
            "content": "Vi bygger faktisk, akkurat nå, uhyggelige, superkompetente, amoralske psykopater som aldri sover, tenker mye raskere enn oss, kan lage kopier av seg selv og ikke har noe menneskelig ved seg i det hele tatt. Hva kan vel gå galt?",
            "author": "Max Tegmark",
            "title": "Professor, MIT; AI-sikkerhetsforsker",
            "date": "Nov 2023",
            "source": "https://www.facebook.com/futureoflifeinstitute/posts/we-are-right-now-building-creepy-super-capable-amoral-psychopaths-that-never-sle/691751266435495/"
          },
          {
            "content": "Selv om vi «vinner» det globale kappløpet om å utvikle disse ukontrollerbare AI-systemene, risikerer vi å miste vår sosiale stabilitet, sikkerhet og muligens til og med vår art i prosessen.",
            "author": "Max Tegmark",
            "title": "Professor, MIT; AI-sikkerhetsforsker",
            "date": "Okt 2023",
            "source": "https://futureoflife.org/open-letters/written-statement-of-dr-max-tegmark-to-the-ai-insight-forum/"
          }
        ] %}
          <div class="quote-card-large">
            <div class="quote-content">
              <p>{{ quote.content }}</p>
              <div class="quote-date-source">{{ quote.date }} - <a href="{{ quote.source }}" target="_blank" rel="noopener noreferrer">Kilde</a></div>
            </div>
            <div class="quote-attribution">
              <div>
                <div class="quote-author">{{ quote.author }}</div>
                <div class="quote-title">{{ quote.title }}</div>
              </div>
            </div>
          </div>
        {% endfor %}
      {% endif %}
    </div>
  </div>
</section>

<section class="call-to-action">
  <div class="container">
    <h2>
      {% if lang == "en" %}
        Join Us in Addressing AI Safety Challenges
      {% else %}
        Bli med oss i arbeidet med AI-sikkerhetsutfordringer
      {% endif %}
    </h2>
    <p>
      {% if lang == "en" %}
        Want to learn more about AI safety or get involved with our work? Reach out to us today.
      {% else %}
        Vil du lære mer om AI-sikkerhet eller bli involvert i vårt arbeid? Ta kontakt med oss i dag.
      {% endif %}
    </p>
    <a href="{{ langUtils.localizeUrl('contact', currentLanguage) }}" role="button">
      {% if lang == "en" %}Contact Us{% else %}Kontakt oss{% endif %}
    </a>
  </div>
</section>
{% endblock %} 